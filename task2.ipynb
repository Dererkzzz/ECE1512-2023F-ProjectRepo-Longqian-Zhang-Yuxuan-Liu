{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dererkzzz/ECE1512-2023F-ProjectRepo-Longqian-Zhang-Yuxuan-Liu/blob/main/task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-Xmy28SnM65"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v2 as tf #\n",
        "from typing import Union\n",
        "from tensorflow.keras.layers import *\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#from keras.utils.np_utils import to_categorical\n",
        "import tensorflow.keras.utils as utils\n",
        "import keras\n",
        "import numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "tf.enable_v2_behavior()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiUwjEVkpx2g",
        "outputId": "72762b67-674f-42de-fc91-b3e438ac11c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "target_directory = r'/content/drive/My Drive/ECE_1512_ProjectA/mhist_dataset/images'\n",
        "os.chdir(target_directory)\n",
        "image_table=pd.read_csv('/content/drive/My Drive/ECE_1512_ProjectA/mhist_dataset/annotations.csv')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WfKeYV2-r26b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train dataset\n"
      ],
      "metadata": {
        "id": "PIlGBSZMvbAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = image_table[image_table['Partition'] == 'train']\n",
        "print(\"Shape of the 'train_set' DataFrame:\")\n",
        "print(train_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WickJH3pvVIw",
        "outputId": "ce24f522-e822-497e-d51a-ad945d8c7482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the 'train_set' DataFrame:\n",
            "(2175, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test dataset"
      ],
      "metadata": {
        "id": "cAKLNA8SvgLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = image_table[image_table['Partition'] == 'test']\n",
        "print(\"Shape of the 'test_set' DataFrame:\")\n",
        "print(test_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yhji4k9kvh3Z",
        "outputId": "2aacfc91-faa2-41a0-9e40-d0bcc828260c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the 'test_set' DataFrame:\n",
            "(977, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = '/content/drive/My Drive//ECE_1512_ProjectA/mhist_dataset/images'"
      ],
      "metadata": {
        "id": "ssFQ0FvHvx4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1/255.0,      # 将像素值缩放到0到1之间\n",
        "    shear_range=-0.1,      # 错切变换范围\n",
        "    rotation_range=15,    # 旋转范围，最多旋转15度\n",
        "    horizontal_flip=True, # 水平翻转\n",
        "    vertical_flip=True,    # 垂直翻转\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1/255.0  # 将像素值缩放到0到1之间\n",
        ")\n"
      ],
      "metadata": {
        "id": "2bzyB1YwyiQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create dataset generator"
      ],
      "metadata": {
        "id": "weo4zQkXzm8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建训练数据生成器\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_set,             # 从数据框中读取训练数据\n",
        "    directory=image_dir,             # 图像所在的目录路径\n",
        "    x_col=\"Image Name\",              # 图像文件名列\n",
        "    y_col=\"Majority Vote Label\",     # 类别标签列\n",
        "    batch_size=32,                   # 批次大小\n",
        "    seed=50,                         # 随机种子，可使生成的数据可重复\n",
        "    shuffle=True,                    # 是否随机洗牌数据\n",
        "    interpolation='lanczos',        # 图像大小调整插值方法\n",
        "    class_mode=\"categorical\",        # 多分类问题\n",
        "    target_size=(224, 224)           # 目标图像大小\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6cGxcLfyqjA",
        "outputId": "4bf3230d-2738-42bf-b183-63e31ff5ef6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2175 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_set,             # 从数据框中读取训练数据\n",
        "    directory=image_dir,             # 图像所在的目录路径\n",
        "    x_col=\"Image Name\",              # 图像文件名列\n",
        "    y_col=\"Majority Vote Label\",     # 类别标签列\n",
        "    batch_size=32,                   # 批次大小\n",
        "    seed=50,                         # 随机种子，可使生成的数据可重复\n",
        "    shuffle=False,                    # 是否随机洗牌数据\n",
        "    interpolation='lanczos',        # 图像大小调整插值方法\n",
        "    class_mode=\"categorical\",        # 多分类问题\n",
        "    target_size=(224, 224)           # 目标图像大小\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVTW91AGztKj",
        "outputId": "d27b1559-f7c2-415f-fb06-2d8ae44241f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 977 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create ResNet50v2 model"
      ],
      "metadata": {
        "id": "KD2b8Nsq1o8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = tf.keras.applications.ResNet50V2(\n",
        "    include_top = False,  # 不包括顶层（全连接层）\n",
        "    weights=\"imagenet\",  # 使用预训练权重\n",
        "    input_tensor=None,  # 没有指定输入张量，将在模型内部创建\n",
        "    input_shape=(224, 224, 3),  # 输入图像的形状为 224x224 像素，RGB通道\n",
        "    pooling='avg'  # 使用全局平均池化层\n",
        ")"
      ],
      "metadata": {
        "id": "L4HJZpRY1Zbu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22724efe-6600-468e-b921-4d8a86100da1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94668760/94668760 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取 ResNet 模型\n",
        "resnet = tf.keras.applications.ResNet50V2(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(224, 224, 3),\n",
        "    pooling='avg'\n",
        ")\n",
        "\n",
        "# 定义要冻结的层的数量\n",
        "freeze_layers = 170\n",
        "\n",
        "# 冻结模型的前 freeze_layers 层\n",
        "for layer in resnet.layers[:freeze_layers]:\n",
        "    layer.trainable = False\n",
        "\n",
        "#输出已冻结层的数量\n",
        "print(f\"frozen {freeze_layers} layer\")"
      ],
      "metadata": {
        "id": "B4-eGCoa2TWs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64282f1c-7cc7-42b3-c4f9-c60c45afeb9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frozen 170 layer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#检查模型层的可训练性质和名称\n",
        "for idx, layer in enumerate(resnet.layers, 1):\n",
        "    print(f\"layer {idx} {layer.trainable},  {layer.name[:5]}\")"
      ],
      "metadata": {
        "id": "xVKzyvEw3ms4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca6d0649-8bd3-41c3-dc21-eda63ef96cd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "layer 1 False,  input\n",
            "layer 2 False,  conv1\n",
            "layer 3 False,  conv1\n",
            "layer 4 False,  pool1\n",
            "layer 5 False,  pool1\n",
            "layer 6 False,  conv2\n",
            "layer 7 False,  conv2\n",
            "layer 8 False,  conv2\n",
            "layer 9 False,  conv2\n",
            "layer 10 False,  conv2\n",
            "layer 11 False,  conv2\n",
            "layer 12 False,  conv2\n",
            "layer 13 False,  conv2\n",
            "layer 14 False,  conv2\n",
            "layer 15 False,  conv2\n",
            "layer 16 False,  conv2\n",
            "layer 17 False,  conv2\n",
            "layer 18 False,  conv2\n",
            "layer 19 False,  conv2\n",
            "layer 20 False,  conv2\n",
            "layer 21 False,  conv2\n",
            "layer 22 False,  conv2\n",
            "layer 23 False,  conv2\n",
            "layer 24 False,  conv2\n",
            "layer 25 False,  conv2\n",
            "layer 26 False,  conv2\n",
            "layer 27 False,  conv2\n",
            "layer 28 False,  conv2\n",
            "layer 29 False,  conv2\n",
            "layer 30 False,  conv2\n",
            "layer 31 False,  conv2\n",
            "layer 32 False,  conv2\n",
            "layer 33 False,  conv2\n",
            "layer 34 False,  conv2\n",
            "layer 35 False,  conv2\n",
            "layer 36 False,  conv2\n",
            "layer 37 False,  conv2\n",
            "layer 38 False,  max_p\n",
            "layer 39 False,  conv2\n",
            "layer 40 False,  conv2\n",
            "layer 41 False,  conv3\n",
            "layer 42 False,  conv3\n",
            "layer 43 False,  conv3\n",
            "layer 44 False,  conv3\n",
            "layer 45 False,  conv3\n",
            "layer 46 False,  conv3\n",
            "layer 47 False,  conv3\n",
            "layer 48 False,  conv3\n",
            "layer 49 False,  conv3\n",
            "layer 50 False,  conv3\n",
            "layer 51 False,  conv3\n",
            "layer 52 False,  conv3\n",
            "layer 53 False,  conv3\n",
            "layer 54 False,  conv3\n",
            "layer 55 False,  conv3\n",
            "layer 56 False,  conv3\n",
            "layer 57 False,  conv3\n",
            "layer 58 False,  conv3\n",
            "layer 59 False,  conv3\n",
            "layer 60 False,  conv3\n",
            "layer 61 False,  conv3\n",
            "layer 62 False,  conv3\n",
            "layer 63 False,  conv3\n",
            "layer 64 False,  conv3\n",
            "layer 65 False,  conv3\n",
            "layer 66 False,  conv3\n",
            "layer 67 False,  conv3\n",
            "layer 68 False,  conv3\n",
            "layer 69 False,  conv3\n",
            "layer 70 False,  conv3\n",
            "layer 71 False,  conv3\n",
            "layer 72 False,  conv3\n",
            "layer 73 False,  conv3\n",
            "layer 74 False,  conv3\n",
            "layer 75 False,  conv3\n",
            "layer 76 False,  conv3\n",
            "layer 77 False,  conv3\n",
            "layer 78 False,  conv3\n",
            "layer 79 False,  conv3\n",
            "layer 80 False,  conv3\n",
            "layer 81 False,  conv3\n",
            "layer 82 False,  conv3\n",
            "layer 83 False,  conv3\n",
            "layer 84 False,  max_p\n",
            "layer 85 False,  conv3\n",
            "layer 86 False,  conv3\n",
            "layer 87 False,  conv4\n",
            "layer 88 False,  conv4\n",
            "layer 89 False,  conv4\n",
            "layer 90 False,  conv4\n",
            "layer 91 False,  conv4\n",
            "layer 92 False,  conv4\n",
            "layer 93 False,  conv4\n",
            "layer 94 False,  conv4\n",
            "layer 95 False,  conv4\n",
            "layer 96 False,  conv4\n",
            "layer 97 False,  conv4\n",
            "layer 98 False,  conv4\n",
            "layer 99 False,  conv4\n",
            "layer 100 False,  conv4\n",
            "layer 101 False,  conv4\n",
            "layer 102 False,  conv4\n",
            "layer 103 False,  conv4\n",
            "layer 104 False,  conv4\n",
            "layer 105 False,  conv4\n",
            "layer 106 False,  conv4\n",
            "layer 107 False,  conv4\n",
            "layer 108 False,  conv4\n",
            "layer 109 False,  conv4\n",
            "layer 110 False,  conv4\n",
            "layer 111 False,  conv4\n",
            "layer 112 False,  conv4\n",
            "layer 113 False,  conv4\n",
            "layer 114 False,  conv4\n",
            "layer 115 False,  conv4\n",
            "layer 116 False,  conv4\n",
            "layer 117 False,  conv4\n",
            "layer 118 False,  conv4\n",
            "layer 119 False,  conv4\n",
            "layer 120 False,  conv4\n",
            "layer 121 False,  conv4\n",
            "layer 122 False,  conv4\n",
            "layer 123 False,  conv4\n",
            "layer 124 False,  conv4\n",
            "layer 125 False,  conv4\n",
            "layer 126 False,  conv4\n",
            "layer 127 False,  conv4\n",
            "layer 128 False,  conv4\n",
            "layer 129 False,  conv4\n",
            "layer 130 False,  conv4\n",
            "layer 131 False,  conv4\n",
            "layer 132 False,  conv4\n",
            "layer 133 False,  conv4\n",
            "layer 134 False,  conv4\n",
            "layer 135 False,  conv4\n",
            "layer 136 False,  conv4\n",
            "layer 137 False,  conv4\n",
            "layer 138 False,  conv4\n",
            "layer 139 False,  conv4\n",
            "layer 140 False,  conv4\n",
            "layer 141 False,  conv4\n",
            "layer 142 False,  conv4\n",
            "layer 143 False,  conv4\n",
            "layer 144 False,  conv4\n",
            "layer 145 False,  conv4\n",
            "layer 146 False,  conv4\n",
            "layer 147 False,  conv4\n",
            "layer 148 False,  conv4\n",
            "layer 149 False,  conv4\n",
            "layer 150 False,  conv4\n",
            "layer 151 False,  conv4\n",
            "layer 152 False,  max_p\n",
            "layer 153 False,  conv4\n",
            "layer 154 False,  conv4\n",
            "layer 155 False,  conv5\n",
            "layer 156 False,  conv5\n",
            "layer 157 False,  conv5\n",
            "layer 158 False,  conv5\n",
            "layer 159 False,  conv5\n",
            "layer 160 False,  conv5\n",
            "layer 161 False,  conv5\n",
            "layer 162 False,  conv5\n",
            "layer 163 False,  conv5\n",
            "layer 164 False,  conv5\n",
            "layer 165 False,  conv5\n",
            "layer 166 False,  conv5\n",
            "layer 167 False,  conv5\n",
            "layer 168 False,  conv5\n",
            "layer 169 False,  conv5\n",
            "layer 170 False,  conv5\n",
            "layer 171 True,  conv5\n",
            "layer 172 True,  conv5\n",
            "layer 173 True,  conv5\n",
            "layer 174 True,  conv5\n",
            "layer 175 True,  conv5\n",
            "layer 176 True,  conv5\n",
            "layer 177 True,  conv5\n",
            "layer 178 True,  conv5\n",
            "layer 179 True,  conv5\n",
            "layer 180 True,  conv5\n",
            "layer 181 True,  conv5\n",
            "layer 182 True,  conv5\n",
            "layer 183 True,  conv5\n",
            "layer 184 True,  conv5\n",
            "layer 185 True,  conv5\n",
            "layer 186 True,  conv5\n",
            "layer 187 True,  conv5\n",
            "layer 188 True,  conv5\n",
            "layer 189 True,  post_\n",
            "layer 190 True,  post_\n",
            "layer 191 True,  avg_p\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建全连接输出层\n",
        "output_layer = tf.keras.layers.Dense(units=2, activation='sigmoid')\n",
        "\n",
        "# 创建教师模型\n",
        "teacher_res = tf.keras.Sequential([resnet, output_layer])\n",
        "teacher_res.summary()"
      ],
      "metadata": {
        "id": "NoXIhlQt4Clg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4c9b7a1-8202-4930-fbe8-e4c27d92c619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 4098      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23568898 (89.91 MB)\n",
            "Trainable params: 7883778 (30.07 MB)\n",
            "Non-trainable params: 15685120 (59.83 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create mobilenet model"
      ],
      "metadata": {
        "id": "pC2brm-K4iMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet = tf.keras.applications.MobileNetV2(\n",
        "    include_top=False,  # 不包括顶层（全连接层）\n",
        "    weights=\"imagenet\",  # 使用预训练权重\n",
        "    input_tensor=None,  # 没有指定输入张量，将在模型内部创建\n",
        "    input_shape=(224, 224, 3),  # 输入图像的形状为 224x224 像素，RGB通道\n",
        "    pooling='max'\n",
        ")"
      ],
      "metadata": {
        "id": "_D2KqK_a4nrg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d5e8b6-1b9e-4f06-e6c2-eabda6c84c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# freeze_layers_start = 'block_11'  # 指定要从哪一层开始冻结\n",
        "# for layer in mobilenet.layers:\n",
        "#     if layer.name.startswith(freeze_layers_start):\n",
        "#         break\n",
        "#     layer.trainable = False\n",
        "\n",
        "# # 输出已冻结层的数量\n",
        "# num_trainable_layers = len([layer for layer in mobilenet.layers if layer.trainable])\n",
        "# print(f\"frozen {len(mobilenet.layers) - num_trainable_layers} layer\")\n",
        "# Making the first 120 layers trainable\n",
        "count=0\n",
        "for layers in mobilenet.layers:\n",
        "  count+=1\n",
        "  if count> 130:\n",
        "    layers.trainable=True\n",
        "  # if(layers.name[0:8]== 'block_13' ):\n",
        "  #   continue\n",
        "  else:\n",
        "    layers.trainable=False\n",
        "print(count)\n"
      ],
      "metadata": {
        "id": "fdIYlrKg5zTN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb67a2b9-6585-4b75-bb05-36706cde9a0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count=0\n",
        "for layers in mobilenet.layers:\n",
        "  print(layers.trainable, layers.name[0:8], count)\n",
        "  count+=1"
      ],
      "metadata": {
        "id": "eiTS6mWh6ZRX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a041ad26-2aef-4874-8806-946910d447a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False input_3 0\n",
            "False Conv1 1\n",
            "False bn_Conv1 2\n",
            "False Conv1_re 3\n",
            "False expanded 4\n",
            "False expanded 5\n",
            "False expanded 6\n",
            "False expanded 7\n",
            "False expanded 8\n",
            "False block_1_ 9\n",
            "False block_1_ 10\n",
            "False block_1_ 11\n",
            "False block_1_ 12\n",
            "False block_1_ 13\n",
            "False block_1_ 14\n",
            "False block_1_ 15\n",
            "False block_1_ 16\n",
            "False block_1_ 17\n",
            "False block_2_ 18\n",
            "False block_2_ 19\n",
            "False block_2_ 20\n",
            "False block_2_ 21\n",
            "False block_2_ 22\n",
            "False block_2_ 23\n",
            "False block_2_ 24\n",
            "False block_2_ 25\n",
            "False block_2_ 26\n",
            "False block_3_ 27\n",
            "False block_3_ 28\n",
            "False block_3_ 29\n",
            "False block_3_ 30\n",
            "False block_3_ 31\n",
            "False block_3_ 32\n",
            "False block_3_ 33\n",
            "False block_3_ 34\n",
            "False block_3_ 35\n",
            "False block_4_ 36\n",
            "False block_4_ 37\n",
            "False block_4_ 38\n",
            "False block_4_ 39\n",
            "False block_4_ 40\n",
            "False block_4_ 41\n",
            "False block_4_ 42\n",
            "False block_4_ 43\n",
            "False block_4_ 44\n",
            "False block_5_ 45\n",
            "False block_5_ 46\n",
            "False block_5_ 47\n",
            "False block_5_ 48\n",
            "False block_5_ 49\n",
            "False block_5_ 50\n",
            "False block_5_ 51\n",
            "False block_5_ 52\n",
            "False block_5_ 53\n",
            "False block_6_ 54\n",
            "False block_6_ 55\n",
            "False block_6_ 56\n",
            "False block_6_ 57\n",
            "False block_6_ 58\n",
            "False block_6_ 59\n",
            "False block_6_ 60\n",
            "False block_6_ 61\n",
            "False block_6_ 62\n",
            "False block_7_ 63\n",
            "False block_7_ 64\n",
            "False block_7_ 65\n",
            "False block_7_ 66\n",
            "False block_7_ 67\n",
            "False block_7_ 68\n",
            "False block_7_ 69\n",
            "False block_7_ 70\n",
            "False block_7_ 71\n",
            "False block_8_ 72\n",
            "False block_8_ 73\n",
            "False block_8_ 74\n",
            "False block_8_ 75\n",
            "False block_8_ 76\n",
            "False block_8_ 77\n",
            "False block_8_ 78\n",
            "False block_8_ 79\n",
            "False block_8_ 80\n",
            "False block_9_ 81\n",
            "False block_9_ 82\n",
            "False block_9_ 83\n",
            "False block_9_ 84\n",
            "False block_9_ 85\n",
            "False block_9_ 86\n",
            "False block_9_ 87\n",
            "False block_9_ 88\n",
            "False block_9_ 89\n",
            "False block_10 90\n",
            "False block_10 91\n",
            "False block_10 92\n",
            "False block_10 93\n",
            "False block_10 94\n",
            "False block_10 95\n",
            "False block_10 96\n",
            "False block_10 97\n",
            "False block_11 98\n",
            "False block_11 99\n",
            "False block_11 100\n",
            "False block_11 101\n",
            "False block_11 102\n",
            "False block_11 103\n",
            "False block_11 104\n",
            "False block_11 105\n",
            "False block_11 106\n",
            "False block_12 107\n",
            "False block_12 108\n",
            "False block_12 109\n",
            "False block_12 110\n",
            "False block_12 111\n",
            "False block_12 112\n",
            "False block_12 113\n",
            "False block_12 114\n",
            "False block_12 115\n",
            "False block_13 116\n",
            "False block_13 117\n",
            "False block_13 118\n",
            "False block_13 119\n",
            "False block_13 120\n",
            "False block_13 121\n",
            "False block_13 122\n",
            "False block_13 123\n",
            "False block_13 124\n",
            "False block_14 125\n",
            "False block_14 126\n",
            "False block_14 127\n",
            "False block_14 128\n",
            "False block_14 129\n",
            "True block_14 130\n",
            "True block_14 131\n",
            "True block_14 132\n",
            "True block_14 133\n",
            "True block_15 134\n",
            "True block_15 135\n",
            "True block_15 136\n",
            "True block_15 137\n",
            "True block_15 138\n",
            "True block_15 139\n",
            "True block_15 140\n",
            "True block_15 141\n",
            "True block_15 142\n",
            "True block_16 143\n",
            "True block_16 144\n",
            "True block_16 145\n",
            "True block_16 146\n",
            "True block_16 147\n",
            "True block_16 148\n",
            "True block_16 149\n",
            "True block_16 150\n",
            "True Conv_1 151\n",
            "True Conv_1_b 152\n",
            "True out_relu 153\n",
            "True global_m 154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_layer = tf.keras.layers.Dense(units=2, activation='sigmoid')\n",
        "\n",
        "# 创建学生模型\n",
        "student_mobile = tf.keras.Sequential([mobilenet, output_layer])"
      ],
      "metadata": {
        "id": "Ptuyn49E7CYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "UDrwS3iJ7iR-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JWGucyrQGav"
      },
      "source": [
        "# Teacher loss function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_teacher_loss(images, labels):\n",
        "  \"\"\"Compute subclass knowledge distillation teacher loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  subclass_logits = teacher_res(images, training=True)\n",
        "\n",
        "  # Compute cross-entropy loss for subclasses.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "  cross_entropy_loss_value = tf.keras.losses.CategoricalCrossentropy(from_logits=True)(labels, subclass_logits)\n",
        "\n",
        "\n",
        "  return cross_entropy_loss_value"
      ],
      "metadata": {
        "id": "5Cuj_pfb9HhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS8xkuH0QbOS"
      },
      "source": [
        "# Student loss function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##@test {\"output\": \"ignore\"}\n",
        "\n",
        "# Hyperparameters for distillation (need to be tuned).\n",
        "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE = 4. #temperature hyperparameter\n",
        "\n",
        "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
        "                      temperature: Union[float, tf.Tensor]):\n",
        "  \"\"\"Compute distillation loss.\n",
        "\n",
        "  This function computes cross entropy between softened logits and softened\n",
        "  targets. The resulting loss is scaled by the squared temperature so that\n",
        "  the gradient magnitude remains approximately constant as the temperature is\n",
        "  changed. For reference, see Hinton et al., 2014, \"Distilling the knowledge in\n",
        "  a neural network.\"\n",
        "\n",
        "  Args:\n",
        "    teacher_logits: A Tensor of logits provided by the teacher.\n",
        "    student_logits: A Tensor of logits provided by the student, of the same\n",
        "      shape as `teacher_logits`.\n",
        "    temperature: Temperature to use for distillation.\n",
        "\n",
        "  Returns:\n",
        "    A scalar Tensor containing the distillation loss.\n",
        "  \"\"\"\n",
        " # your code start from here for step 3\n",
        "  soft_targets = tf.nn.softmax(teacher_logits/temperature)\n",
        "\n",
        "  return tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(\n",
        "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
        "\n",
        "def compute_student_loss(images, labels, ALPHA, DISTILLATION_TEMPERATURE):\n",
        "  \"\"\"Compute subclass knowledge distillation student loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  student_subclass_logits = student_mobile(images, training=True) # fc model\n",
        "\n",
        "  # Compute subclass distillation loss between student subclass logits and\n",
        "  # softened teacher subclass targets probabilities.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  teacher_subclass_logits = teacher_res(images, training=False) # cnn_model\n",
        "  distillation_loss_value = distillation_loss(teacher_subclass_logits, student_subclass_logits,\n",
        "                      DISTILLATION_TEMPERATURE)\n",
        "\n",
        "  # Compute cross-entropy loss with hard targets.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  cross_entropy_loss_value = tf.keras.losses.CategoricalCrossentropy(from_logits=True)(labels, student_subclass_logits)\n",
        "\n",
        "  return ALPHA * distillation_loss_value + (1-ALPHA)* cross_entropy_loss_value"
      ],
      "metadata": {
        "id": "J6xV9FbN9P43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train and evaluation\n"
      ],
      "metadata": {
        "id": "wHF_CTM72yD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_num_correct(model, images, labels):\n",
        "  \"\"\"Compute number of correctly classified images in a batch.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Number of correctly classified images.\n",
        "  \"\"\"\n",
        "  class_logits = model(images, training=False)\n",
        "  return tf.reduce_sum(\n",
        "      tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),\n",
        "              tf.float32)), tf.argmax(class_logits, -1), tf.argmax(labels, -1)\n",
        "\n",
        "\n",
        "def train_and_evaluate_teacher(model, compute_loss_fn, num_epochs=10):\n",
        "    \"\"\"Train and evaluate the teacher model.\n",
        "\n",
        "    Args:\n",
        "        model: Instance of tf.keras.Model.\n",
        "        compute_loss_fn: A function to compute training loss from images and labels.\n",
        "        num_epochs: Number of training epochs.\n",
        "    \"\"\"\n",
        "\n",
        "    # Set the optimizer for training.\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "    # Training loop for the specified number of epochs.\n",
        "    for epoch in range(1, num_epochs + 1):\n",
        "        print('Epoch {}: '.format(epoch), end='')\n",
        "\n",
        "        # Reset the training data generator.\n",
        "        train_generator.reset()\n",
        "\n",
        "        # Loop through batches for training.\n",
        "        for _ in range(68):\n",
        "            images, labels = train_generator.next()\n",
        "\n",
        "            # Calculate loss and gradients.\n",
        "            with tf.GradientTape() as tape:\n",
        "                loss_value = compute_loss_fn(images, labels)\n",
        "\n",
        "            grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "\n",
        "            # Apply gradients to update model parameters.\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        # Evaluate the model after each epoch.\n",
        "        num_correct = 0\n",
        "        num_total = 0\n",
        "\n",
        "        for _ in range(31):\n",
        "            images, labels = test_generator.next()\n",
        "            num_total += len(labels)\n",
        "            num_correct += compute_num_correct(model, images, labels)[0]\n",
        "\n",
        "        print(\"Class accuracy: \" + '{:.2f}%'.format(num_correct / num_total * 100))\n",
        "\n",
        "    # Fine-tuning phase.\n",
        "    print('Fine-tuning')\n",
        "\n",
        "    # Set the optimizer for fine-tuning.\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "\n",
        "    # Get the specific layer for fine-tuning.\n",
        "    # m = teacher_res.get_layer('resnet50v2')\n",
        "    # count = 0\n",
        "\n",
        "    # Fine-tune specific layers.\n",
        "    # for layers in m.layers:\n",
        "    #     count += 1\n",
        "    #     if count == 152 or layers.name[0:5] == 'conv4':\n",
        "    #         layers.trainable = True\n",
        "    #     else:\n",
        "    #         continue\n",
        "\n",
        "    m=teacher_res.get_layer('resnet50v2')\n",
        "    count = 0\n",
        "    for layers in m.layers:\n",
        "      count+=1\n",
        "      print(layers.trainable, layers.name[0:5], count)\n",
        "\n",
        "\n",
        "    # Training loop for fine-tuning.\n",
        "    for epoch in range(1, 25 + 1):\n",
        "        print('Epoch {}: '.format(epoch), end='')\n",
        "\n",
        "        # Reset the training data generator.\n",
        "        train_generator.reset()\n",
        "\n",
        "        # Loop through batches for fine-tuning.\n",
        "        for _ in range(68):\n",
        "            images, labels = train_generator.next()\n",
        "\n",
        "            # Calculate loss and gradients.\n",
        "            with tf.GradientTape() as tape:\n",
        "                loss_value = compute_loss_fn(images, labels)\n",
        "\n",
        "            grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "\n",
        "            # Apply gradients to update model parameters.\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "        # Evaluate the model during fine-tuning.\n",
        "        num_correct = 0\n",
        "        num_total = 0\n",
        "\n",
        "        for _ in range(31):\n",
        "            images, labels = test_generator.next()\n",
        "            num_total += len(labels)\n",
        "            num_correct += compute_num_correct(model, images, labels)[0]\n",
        "\n",
        "        print(\"Class accuracy: \" + '{:.2f}%'.format(num_correct / num_total * 100))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QT9rVAug-XHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_kd(model, compute_loss_fn, ALPHA=0.8, DISTILLATION_TEMPERATURE=8.):\n",
        "  \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # your code start from here for step 4\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "  for epoch in range(1,11):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    train_generator.reset()\n",
        "    for _ in range(68):\n",
        "      images, labels=train_generator.next()\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4\n",
        "\n",
        "        loss_value = compute_loss_fn(images,labels, ALPHA, DISTILLATION_TEMPERATURE)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    for _ in range(31):\n",
        "      # your code start from here for step 4\n",
        "      images, labels=test_generator.next()\n",
        "      num_total+= len(labels)\n",
        "      num_correct += compute_num_correct(model,images,labels)[0]\n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n",
        "\n",
        "  #fine tuning\n",
        "  print('fine tuning')\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "  m=student_mobile.get_layer('mobilenetv2_1.00_224')\n",
        "\n",
        "  count=0\n",
        "  for layers in m.layers:\n",
        "    count+=1\n",
        "    print(layers.trainable, layers.name[0:8], count)\n",
        "\n",
        "  for epoch in range(1,26):\n",
        "  # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    train_generator.reset()\n",
        "    for _ in range(68):\n",
        "      images, labels=train_generator.next()\n",
        "      with tf.GradientTape() as tape:\n",
        "        # your code start from here for step 4\n",
        "\n",
        "        loss_value = compute_loss_fn(images,labels, ALPHA, DISTILLATION_TEMPERATURE)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    for _ in range(31):\n",
        "      # your code start from here for step 4\n",
        "      images, labels=test_generator.next()\n",
        "      num_total+= len(labels)\n",
        "      num_correct += compute_num_correct(model,images,labels)[0]\n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))"
      ],
      "metadata": {
        "id": "yOBtEK3Z306L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_no_kd(model, compute_loss_fn):\n",
        "  \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # your code start from here for step 4\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "  for epoch in range(10):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    train_generator.reset()\n",
        "    for _ in range(68):\n",
        "      images, labels=train_generator.next()\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4\n",
        "\n",
        "        loss_value = compute_loss_fn(images,labels)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "          # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    for _ in range(31):\n",
        "      # your code start from here for step 4\n",
        "      images, labels=test_generator.next()\n",
        "      num_total+= len(labels)\n",
        "      num_correct += compute_num_correct(model,images,labels)[0]\n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n",
        "\n",
        "  #fine tuning\n",
        "  print('fine tuning')\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "  m=student_mobile.get_layer('mobilenetv2_1.00_224')\n",
        "  count=0\n",
        "  for layers in m.layers:\n",
        "    count+=1\n",
        "    print(layers.trainable, layers.name[0:8], count)\n",
        "\n",
        "  for epoch in range(25):\n",
        "  # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    train_generator.reset()\n",
        "    for _ in range(68):\n",
        "      images, labels=train_generator.next()\n",
        "      with tf.GradientTape() as tape:\n",
        "        # your code start from here for step 4\n",
        "\n",
        "        loss_value = compute_loss_fn(images,labels)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    for _ in range(31):\n",
        "      # your code start from here for step 4\n",
        "      images, labels=test_generator.next()\n",
        "      num_total+= len(labels)\n",
        "      num_correct += compute_num_correct(model,images,labels)[0]\n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n"
      ],
      "metadata": {
        "id": "CaqgGJka31DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_plain_cross_entropy_loss_mobile(images, labels):\n",
        "  \"\"\"Compute plain loss for given images and labels.\n",
        "\n",
        "  For fair comparison and convenience, this function also performs a\n",
        "  LogSumExp over subclasses, but does not perform subclass distillation.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  # your code start from here for step 7\n",
        "\n",
        "  student_subclass_logits = student_mobile(images, training=True)\n",
        "  cross_entropy_loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)(labels, student_subclass_logits)\n",
        "\n",
        "  return cross_entropy_loss"
      ],
      "metadata": {
        "id": "w-QDz8Rv31Kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training"
      ],
      "metadata": {
        "id": "nNfvWOlg32XQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate_teacher(teacher_res,compute_teacher_loss)"
      ],
      "metadata": {
        "id": "FEtaowRo31Ry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b83a6c39-2b9a-4f99-a95e-b4fafff1d350"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5577: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7c6bbc382c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7c6bbc382c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class accuracy: 78.20%\n",
            "Epoch 2: Class accuracy: 79.53%\n",
            "Epoch 3: Class accuracy: 81.47%\n",
            "Epoch 4: Class accuracy: 81.27%\n",
            "Epoch 5: Class accuracy: 79.63%\n",
            "Epoch 6: Class accuracy: 80.45%\n",
            "Epoch 7: Class accuracy: 81.37%\n",
            "Epoch 8: Class accuracy: 81.06%\n",
            "Epoch 9: Class accuracy: 82.19%\n",
            "Epoch 10: Class accuracy: 81.88%\n",
            "Fine-tuning\n",
            "False input 1\n",
            "False conv1 2\n",
            "False conv1 3\n",
            "False pool1 4\n",
            "False pool1 5\n",
            "False conv2 6\n",
            "False conv2 7\n",
            "False conv2 8\n",
            "False conv2 9\n",
            "False conv2 10\n",
            "False conv2 11\n",
            "False conv2 12\n",
            "False conv2 13\n",
            "False conv2 14\n",
            "False conv2 15\n",
            "False conv2 16\n",
            "False conv2 17\n",
            "False conv2 18\n",
            "False conv2 19\n",
            "False conv2 20\n",
            "False conv2 21\n",
            "False conv2 22\n",
            "False conv2 23\n",
            "False conv2 24\n",
            "False conv2 25\n",
            "False conv2 26\n",
            "False conv2 27\n",
            "False conv2 28\n",
            "False conv2 29\n",
            "False conv2 30\n",
            "False conv2 31\n",
            "False conv2 32\n",
            "False conv2 33\n",
            "False conv2 34\n",
            "False conv2 35\n",
            "False conv2 36\n",
            "False conv2 37\n",
            "False max_p 38\n",
            "False conv2 39\n",
            "False conv2 40\n",
            "False conv3 41\n",
            "False conv3 42\n",
            "False conv3 43\n",
            "False conv3 44\n",
            "False conv3 45\n",
            "False conv3 46\n",
            "False conv3 47\n",
            "False conv3 48\n",
            "False conv3 49\n",
            "False conv3 50\n",
            "False conv3 51\n",
            "False conv3 52\n",
            "False conv3 53\n",
            "False conv3 54\n",
            "False conv3 55\n",
            "False conv3 56\n",
            "False conv3 57\n",
            "False conv3 58\n",
            "False conv3 59\n",
            "False conv3 60\n",
            "False conv3 61\n",
            "False conv3 62\n",
            "False conv3 63\n",
            "False conv3 64\n",
            "False conv3 65\n",
            "False conv3 66\n",
            "False conv3 67\n",
            "False conv3 68\n",
            "False conv3 69\n",
            "False conv3 70\n",
            "False conv3 71\n",
            "False conv3 72\n",
            "False conv3 73\n",
            "False conv3 74\n",
            "False conv3 75\n",
            "False conv3 76\n",
            "False conv3 77\n",
            "False conv3 78\n",
            "False conv3 79\n",
            "False conv3 80\n",
            "False conv3 81\n",
            "False conv3 82\n",
            "False conv3 83\n",
            "False max_p 84\n",
            "False conv3 85\n",
            "False conv3 86\n",
            "False conv4 87\n",
            "False conv4 88\n",
            "False conv4 89\n",
            "False conv4 90\n",
            "False conv4 91\n",
            "False conv4 92\n",
            "False conv4 93\n",
            "False conv4 94\n",
            "False conv4 95\n",
            "False conv4 96\n",
            "False conv4 97\n",
            "False conv4 98\n",
            "False conv4 99\n",
            "False conv4 100\n",
            "False conv4 101\n",
            "False conv4 102\n",
            "False conv4 103\n",
            "False conv4 104\n",
            "False conv4 105\n",
            "False conv4 106\n",
            "False conv4 107\n",
            "False conv4 108\n",
            "False conv4 109\n",
            "False conv4 110\n",
            "False conv4 111\n",
            "False conv4 112\n",
            "False conv4 113\n",
            "False conv4 114\n",
            "False conv4 115\n",
            "False conv4 116\n",
            "False conv4 117\n",
            "False conv4 118\n",
            "False conv4 119\n",
            "False conv4 120\n",
            "False conv4 121\n",
            "False conv4 122\n",
            "False conv4 123\n",
            "False conv4 124\n",
            "False conv4 125\n",
            "False conv4 126\n",
            "False conv4 127\n",
            "False conv4 128\n",
            "False conv4 129\n",
            "False conv4 130\n",
            "False conv4 131\n",
            "False conv4 132\n",
            "False conv4 133\n",
            "False conv4 134\n",
            "False conv4 135\n",
            "False conv4 136\n",
            "False conv4 137\n",
            "False conv4 138\n",
            "False conv4 139\n",
            "False conv4 140\n",
            "False conv4 141\n",
            "False conv4 142\n",
            "False conv4 143\n",
            "False conv4 144\n",
            "False conv4 145\n",
            "False conv4 146\n",
            "False conv4 147\n",
            "False conv4 148\n",
            "False conv4 149\n",
            "False conv4 150\n",
            "False conv4 151\n",
            "False max_p 152\n",
            "False conv4 153\n",
            "False conv4 154\n",
            "False conv5 155\n",
            "False conv5 156\n",
            "False conv5 157\n",
            "False conv5 158\n",
            "False conv5 159\n",
            "False conv5 160\n",
            "False conv5 161\n",
            "False conv5 162\n",
            "False conv5 163\n",
            "False conv5 164\n",
            "False conv5 165\n",
            "False conv5 166\n",
            "False conv5 167\n",
            "False conv5 168\n",
            "False conv5 169\n",
            "False conv5 170\n",
            "True conv5 171\n",
            "True conv5 172\n",
            "True conv5 173\n",
            "True conv5 174\n",
            "True conv5 175\n",
            "True conv5 176\n",
            "True conv5 177\n",
            "True conv5 178\n",
            "True conv5 179\n",
            "True conv5 180\n",
            "True conv5 181\n",
            "True conv5 182\n",
            "True conv5 183\n",
            "True conv5 184\n",
            "True conv5 185\n",
            "True conv5 186\n",
            "True conv5 187\n",
            "True conv5 188\n",
            "True post_ 189\n",
            "True post_ 190\n",
            "True avg_p 191\n",
            "Epoch 1: Class accuracy: 83.83%\n",
            "Epoch 2: Class accuracy: 83.21%\n",
            "Epoch 3: Class accuracy: 83.83%\n",
            "Epoch 4: Class accuracy: 83.42%\n",
            "Epoch 5: Class accuracy: 83.21%\n",
            "Epoch 6: Class accuracy: 84.34%\n",
            "Epoch 7: Class accuracy: 83.83%\n",
            "Epoch 8: Class accuracy: 84.14%\n",
            "Epoch 9: Class accuracy: 84.34%\n",
            "Epoch 10: Class accuracy: 84.54%\n",
            "Epoch 11: Class accuracy: 84.24%\n",
            "Epoch 12: Class accuracy: 83.42%\n",
            "Epoch 13: Class accuracy: 83.52%\n",
            "Epoch 14: Class accuracy: 83.62%\n",
            "Epoch 15: Class accuracy: 83.42%\n",
            "Epoch 16: Class accuracy: 83.62%\n",
            "Epoch 17: Class accuracy: 83.01%\n",
            "Epoch 18: Class accuracy: 84.03%\n",
            "Epoch 19: Class accuracy: 84.44%\n",
            "Epoch 20: Class accuracy: 84.54%\n",
            "Epoch 21: Class accuracy: 83.93%\n",
            "Epoch 22: Class accuracy: 84.54%\n",
            "Epoch 23: Class accuracy: 83.73%\n",
            "Epoch 24: Class accuracy: 84.14%\n",
            "Epoch 25: Class accuracy: 83.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/My Drive/ECE_1512_ProjectA/mhist_dataset/teacher_res_new'\n",
        "tf.keras.models.save_model(teacher_res, model_path)\n",
        "loaded_model = tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_imVIJ1f-0Z",
        "outputId": "e21d62f8-46ac-4022-e367-85751525138d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate_no_kd(student_mobile, compute_plain_cross_entropy_loss_mobile)"
      ],
      "metadata": {
        "id": "OwCmMn7sf-no"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/My Drive/ECE_1512_ProjectA/mhist_dataset/mobilenet_no_kd_new'\n",
        "tf.keras.models.save_model(student_mobile, model_path)\n",
        "loaded_model = tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "3keqTlAqgdDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/My Drive/ECE_1512_ProjectA/mhist_dataset/student_mobile_new'\n",
        "tf.keras.models.save_model(student_mobile, model_path)\n",
        "loaded_model = tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "id": "wrh766lZgc08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78b702ce-3519-459c-adf3-38048033d7e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate_kd(student_mobile, compute_student_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o6xsrCCM0PO",
        "outputId": "e5322777-0add-4388-db8e-786954671d8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5577: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class_accuracy: 68.47%\n",
            "Epoch 2: Class_accuracy: 71.65%\n",
            "Epoch 3: Class_accuracy: 72.57%\n",
            "Epoch 4: Class_accuracy: 77.28%\n",
            "Epoch 5: Class_accuracy: 71.75%\n",
            "Epoch 6: Class_accuracy: 74.72%\n",
            "Epoch 7: Class_accuracy: 70.93%\n",
            "Epoch 8: Class_accuracy: 69.91%\n",
            "Epoch 9: Class_accuracy: 80.35%\n",
            "Epoch 10: Class_accuracy: 75.95%\n",
            "fine tuning\n",
            "False input_3 1\n",
            "False Conv1 2\n",
            "False bn_Conv1 3\n",
            "False Conv1_re 4\n",
            "False expanded 5\n",
            "False expanded 6\n",
            "False expanded 7\n",
            "False expanded 8\n",
            "False expanded 9\n",
            "False block_1_ 10\n",
            "False block_1_ 11\n",
            "False block_1_ 12\n",
            "False block_1_ 13\n",
            "False block_1_ 14\n",
            "False block_1_ 15\n",
            "False block_1_ 16\n",
            "False block_1_ 17\n",
            "False block_1_ 18\n",
            "False block_2_ 19\n",
            "False block_2_ 20\n",
            "False block_2_ 21\n",
            "False block_2_ 22\n",
            "False block_2_ 23\n",
            "False block_2_ 24\n",
            "False block_2_ 25\n",
            "False block_2_ 26\n",
            "False block_2_ 27\n",
            "False block_3_ 28\n",
            "False block_3_ 29\n",
            "False block_3_ 30\n",
            "False block_3_ 31\n",
            "False block_3_ 32\n",
            "False block_3_ 33\n",
            "False block_3_ 34\n",
            "False block_3_ 35\n",
            "False block_3_ 36\n",
            "False block_4_ 37\n",
            "False block_4_ 38\n",
            "False block_4_ 39\n",
            "False block_4_ 40\n",
            "False block_4_ 41\n",
            "False block_4_ 42\n",
            "False block_4_ 43\n",
            "False block_4_ 44\n",
            "False block_4_ 45\n",
            "False block_5_ 46\n",
            "False block_5_ 47\n",
            "False block_5_ 48\n",
            "False block_5_ 49\n",
            "False block_5_ 50\n",
            "False block_5_ 51\n",
            "False block_5_ 52\n",
            "False block_5_ 53\n",
            "False block_5_ 54\n",
            "False block_6_ 55\n",
            "False block_6_ 56\n",
            "False block_6_ 57\n",
            "False block_6_ 58\n",
            "False block_6_ 59\n",
            "False block_6_ 60\n",
            "False block_6_ 61\n",
            "False block_6_ 62\n",
            "False block_6_ 63\n",
            "False block_7_ 64\n",
            "False block_7_ 65\n",
            "False block_7_ 66\n",
            "False block_7_ 67\n",
            "False block_7_ 68\n",
            "False block_7_ 69\n",
            "False block_7_ 70\n",
            "False block_7_ 71\n",
            "False block_7_ 72\n",
            "False block_8_ 73\n",
            "False block_8_ 74\n",
            "False block_8_ 75\n",
            "False block_8_ 76\n",
            "False block_8_ 77\n",
            "False block_8_ 78\n",
            "False block_8_ 79\n",
            "False block_8_ 80\n",
            "False block_8_ 81\n",
            "False block_9_ 82\n",
            "False block_9_ 83\n",
            "False block_9_ 84\n",
            "False block_9_ 85\n",
            "False block_9_ 86\n",
            "False block_9_ 87\n",
            "False block_9_ 88\n",
            "False block_9_ 89\n",
            "False block_9_ 90\n",
            "False block_10 91\n",
            "False block_10 92\n",
            "False block_10 93\n",
            "False block_10 94\n",
            "False block_10 95\n",
            "False block_10 96\n",
            "False block_10 97\n",
            "False block_10 98\n",
            "False block_11 99\n",
            "False block_11 100\n",
            "False block_11 101\n",
            "False block_11 102\n",
            "False block_11 103\n",
            "False block_11 104\n",
            "False block_11 105\n",
            "False block_11 106\n",
            "False block_11 107\n",
            "False block_12 108\n",
            "False block_12 109\n",
            "False block_12 110\n",
            "False block_12 111\n",
            "False block_12 112\n",
            "False block_12 113\n",
            "False block_12 114\n",
            "False block_12 115\n",
            "False block_12 116\n",
            "False block_13 117\n",
            "False block_13 118\n",
            "False block_13 119\n",
            "False block_13 120\n",
            "False block_13 121\n",
            "False block_13 122\n",
            "False block_13 123\n",
            "False block_13 124\n",
            "False block_13 125\n",
            "False block_14 126\n",
            "False block_14 127\n",
            "False block_14 128\n",
            "False block_14 129\n",
            "False block_14 130\n",
            "True block_14 131\n",
            "True block_14 132\n",
            "True block_14 133\n",
            "True block_14 134\n",
            "True block_15 135\n",
            "True block_15 136\n",
            "True block_15 137\n",
            "True block_15 138\n",
            "True block_15 139\n",
            "True block_15 140\n",
            "True block_15 141\n",
            "True block_15 142\n",
            "True block_15 143\n",
            "True block_16 144\n",
            "True block_16 145\n",
            "True block_16 146\n",
            "True block_16 147\n",
            "True block_16 148\n",
            "True block_16 149\n",
            "True block_16 150\n",
            "True block_16 151\n",
            "True Conv_1 152\n",
            "True Conv_1_b 153\n",
            "True out_relu 154\n",
            "True global_m 155\n",
            "Epoch 1: Class_accuracy: 78.71%\n",
            "Epoch 2: Class_accuracy: 79.32%\n",
            "Epoch 3: Class_accuracy: 79.43%\n",
            "Epoch 4: Class_accuracy: 79.73%\n",
            "Epoch 5: Class_accuracy: 79.02%\n",
            "Epoch 6: Class_accuracy: 79.32%\n",
            "Epoch 7: Class_accuracy: 78.81%\n",
            "Epoch 8: Class_accuracy: 80.04%\n",
            "Epoch 9: Class_accuracy: 80.66%\n",
            "Epoch 10: Class_accuracy: 80.14%\n",
            "Epoch 11: Class_accuracy: 80.25%\n",
            "Epoch 12: Class_accuracy: 80.25%\n",
            "Epoch 13: Class_accuracy: 80.25%\n",
            "Epoch 14: Class_accuracy: 80.45%\n",
            "Epoch 15: Class_accuracy: 80.66%\n",
            "Epoch 16: Class_accuracy: 80.76%\n",
            "Epoch 17: Class_accuracy: 80.25%\n",
            "Epoch 18: Class_accuracy: 80.04%\n",
            "Epoch 19: Class_accuracy: 80.45%\n",
            "Epoch 20: Class_accuracy: 80.45%\n",
            "Epoch 21: Class_accuracy: 80.45%\n",
            "Epoch 22: Class_accuracy: 80.45%\n",
            "Epoch 23: Class_accuracy: 78.81%\n",
            "Epoch 24: Class_accuracy: 82.19%\n",
            "Epoch 25: Class_accuracy: 81.17%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = '/content/drive/My Drive/ECE_1512_ProjectA/mhist_dataset/student_mobile_kd'\n",
        "tf.keras.models.save_model(student_mobile, model_path)\n",
        "loaded_model = tf.keras.models.load_model(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rShhRKKdNEDv",
        "outputId": "1e8412f0-1a5f-4cf9-d504-a4b6dfadeb68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GGCC7uACgcqi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}