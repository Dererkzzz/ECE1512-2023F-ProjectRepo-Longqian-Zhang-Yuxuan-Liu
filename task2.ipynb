{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP97VrRAFJxqXQKD3yndJkH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dererkzzz/ECE1512-2023F-ProjectRepo-Longqian-Zhang-Yuxuan-Liu/blob/main/task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "O-Xmy28SnM65"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v2 as tf #\n",
        "from typing import Union\n",
        "from tensorflow.keras.layers import *\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "#from keras.utils.np_utils import to_categorical\n",
        "import tensorflow.keras.utils as utils\n",
        "import keras\n",
        "import numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "tf.enable_v2_behavior()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiUwjEVkpx2g",
        "outputId": "83f2c39a-2488-4f78-eeab-126c2f929c3a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "target_directory = r'/content/drive/My Drive/ECE_1512_ProjectA/mhist_dataset/images'\n",
        "os.chdir(target_directory)\n",
        "image_table=pd.read_csv('/content/drive/My Drive/ECE_1512_ProjectA/mhist_dataset/annotations.csv')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfKeYV2-r26b",
        "outputId": "7213e81e-7363-49ea-a037-0582d3125086"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the 'train_set' DataFrame:\n",
            "(2175, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train dataset\n"
      ],
      "metadata": {
        "id": "PIlGBSZMvbAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = image_table[image_table['Partition'] == 'train']\n",
        "print(\"Shape of the 'train_set' DataFrame:\")\n",
        "print(train_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WickJH3pvVIw",
        "outputId": "3a2189cb-24b7-4e69-a339-2fd18591e4b8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the 'train_set' DataFrame:\n",
            "(2175, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test dataset"
      ],
      "metadata": {
        "id": "cAKLNA8SvgLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set = image_table[image_table['Partition'] == 'test']\n",
        "print(\"Shape of the 'test_set' DataFrame:\")\n",
        "print(test_set.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yhji4k9kvh3Z",
        "outputId": "d361fe85-4bf6-44fc-be2c-28781635e21e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the 'test_set' DataFrame:\n",
            "(977, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = '/content/drive/My Drive//ECE_1512_ProjectA/mhist_dataset/images'"
      ],
      "metadata": {
        "id": "ssFQ0FvHvx4C"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1/255.0,      # 将像素值缩放到0到1之间\n",
        "    shear_range=0.1,      # 错切变换范围\n",
        "    rotation_range=15,    # 旋转范围，最多旋转15度\n",
        "    horizontal_flip=True, # 水平翻转\n",
        "    vertical_flip=True    # 垂直翻转\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "    rescale=1/255.0  # 将像素值缩放到0到1之间\n",
        ")\n"
      ],
      "metadata": {
        "id": "2bzyB1YwyiQ_"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "create dataset generator"
      ],
      "metadata": {
        "id": "weo4zQkXzm8a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建训练数据生成器\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_set,             # 从数据框中读取训练数据\n",
        "    directory=image_dir,             # 图像所在的目录路径\n",
        "    x_col=\"Image Name\",              # 图像文件名列\n",
        "    y_col=\"Majority Vote Label\",     # 类别标签列\n",
        "    batch_size=32,                   # 批次大小\n",
        "    seed=42,                         # 随机种子，可使生成的数据可重复\n",
        "    shuffle=True,                    # 是否随机洗牌数据\n",
        "    interpolation='bilinear',        # 图像大小调整插值方法\n",
        "    class_mode=\"categorical\",        # 多分类问题\n",
        "    target_size=(224, 224)           # 目标图像大小\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6cGxcLfyqjA",
        "outputId": "4672ef0f-ec6e-44e1-fe54-c5db8a4a66b8"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2175 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_dataframe(\n",
        "    dataframe=test_set,             # 从数据框中读取训练数据\n",
        "    directory=image_dir,             # 图像所在的目录路径\n",
        "    x_col=\"Image Name\",              # 图像文件名列\n",
        "    y_col=\"Majority Vote Label\",     # 类别标签列\n",
        "    batch_size=32,                   # 批次大小\n",
        "    seed=42,                         # 随机种子，可使生成的数据可重复\n",
        "    shuffle=False,                    # 是否随机洗牌数据\n",
        "    interpolation='bilinear',        # 图像大小调整插值方法\n",
        "    class_mode=\"categorical\",        # 多分类问题\n",
        "    target_size=(224, 224)           # 目标图像大小\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVTW91AGztKj",
        "outputId": "85a6b3eb-85e4-44f9-b6cb-88d3d2363bc5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 977 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create ResNet50v2 model"
      ],
      "metadata": {
        "id": "KD2b8Nsq1o8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet = tf.keras.applications.ResNet50V2(\n",
        "    include_top=False,  # 不包括顶层（全连接层）\n",
        "    weights=\"imagenet\",  # 使用预训练权重\n",
        "    input_tensor=None,  # 没有指定输入张量，将在模型内部创建\n",
        "    input_shape=(224, 224, 3),  # 输入图像的形状为 224x224 像素，RGB通道\n",
        "    pooling='avg'  # 使用全局平均池化层\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4HJZpRY1Zbu",
        "outputId": "d5977e17-766d-446d-ca40-d84411e43d1d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94668760/94668760 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 获取 ResNet 模型\n",
        "resnet = tf.keras.applications.ResNet50V2(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(224, 224, 3),\n",
        "    pooling='avg'\n",
        ")\n",
        "\n",
        "# 定义要冻结的层的数量\n",
        "freeze_layers = 191\n",
        "\n",
        "# 冻结模型的前 freeze_layers 层\n",
        "for layer in resnet.layers[:freeze_layers]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 输出已冻结层的数量\n",
        "print(f\"frozen {freeze_layers} layer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4-eGCoa2TWs",
        "outputId": "72e097af-04d9-4726-dfac-3c901e8d47f3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frozen 191 layer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 检查模型层的可训练性质和名称\n",
        "for idx, layer in enumerate(resnet.layers, 1):\n",
        "    print(f\"layer {idx} {layer.trainable},  {layer.name[:5]}\")"
      ],
      "metadata": {
        "id": "xVKzyvEw3ms4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建全连接输出层\n",
        "output_layer = tf.keras.layers.Dense(units=2, activation='linear')\n",
        "\n",
        "# 创建教师模型\n",
        "teacher_res = tf.keras.Sequential([resnet, output_layer])\n",
        "#teacher_res.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoXIhlQt4Clg",
        "outputId": "4d9f0814-bcab-4da9-ae95-fba1cbe7c036"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 4098      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23568898 (89.91 MB)\n",
            "Trainable params: 4098 (16.01 KB)\n",
            "Non-trainable params: 23564800 (89.89 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create mobilenet model"
      ],
      "metadata": {
        "id": "pC2brm-K4iMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet = tf.keras.applications.MobileNetV2(\n",
        "    include_top=False,  # 不包括顶层（全连接层）\n",
        "    weights=\"imagenet\",  # 使用预训练权重\n",
        "    input_tensor=None,  # 没有指定输入张量，将在模型内部创建\n",
        "    input_shape=(224, 224, 3),  # 输入图像的形状为 224x224 像素，RGB通道\n",
        "    pooling='max'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_D2KqK_a4nrg",
        "outputId": "5110af0d-38c4-467f-e3d0-7b57456d050c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "freeze_layers_start = 'block_16'  # 指定要从哪一层开始冻结\n",
        "for layer in mobilenet.layers:\n",
        "    if layer.name.startswith(freeze_layers_start):\n",
        "        break\n",
        "    layer.trainable = False\n",
        "\n",
        "# 输出已冻结层的数量\n",
        "num_trainable_layers = len([layer for layer in mobilenet.layers if layer.trainable])\n",
        "print(f\"frozen {len(mobilenet.layers) - num_trainable_layers} layer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdIYlrKg5zTN",
        "outputId": "49b0bbdd-a100-42fd-d078-291389adf76b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "frozen 143 layer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, layer in enumerate(mobilenet.layers, 1):\n",
        "    trainable_status = \"Trainable\" if layer.trainable else \"Frozen\"\n",
        "    layer_name = layer.name[:8]  # 获取前8个字符的名称\n",
        "    print(f\"layer{idx}: {trainable_status} {layer_name}\")"
      ],
      "metadata": {
        "id": "eiTS6mWh6ZRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_layer = tf.keras.layers.Dense(units=2, activation='linear')\n",
        "\n",
        "# 创建学生模型\n",
        "student_mobile = tf.keras.Sequential([mobilenet, output_layer])"
      ],
      "metadata": {
        "id": "Ptuyn49E7CYY"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "UDrwS3iJ7iR-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JWGucyrQGav"
      },
      "source": [
        "# Teacher loss function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def compute_teacher_loss(images, labels):\n",
        "  \"\"\"Compute subclass knowledge distillation teacher loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  subclass_logits = teacher_res(images, training=True)\n",
        "\n",
        "  # Compute cross-entropy loss for subclasses.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "  cross_entropy_loss_value = tf.keras.losses.CategoricalCrossentropy(from_logits=True)(labels, subclass_logits)\n",
        "\n",
        "\n",
        "  return cross_entropy_loss_value"
      ],
      "metadata": {
        "id": "5Cuj_pfb9HhX"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS8xkuH0QbOS"
      },
      "source": [
        "# Student loss function"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##@test {\"output\": \"ignore\"}\n",
        "\n",
        "# Hyperparameters for distillation (need to be tuned).\n",
        "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE = 4. #temperature hyperparameter\n",
        "\n",
        "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
        "                      temperature: Union[float, tf.Tensor]):\n",
        "  \"\"\"Compute distillation loss.\n",
        "\n",
        "  This function computes cross entropy between softened logits and softened\n",
        "  targets. The resulting loss is scaled by the squared temperature so that\n",
        "  the gradient magnitude remains approximately constant as the temperature is\n",
        "  changed. For reference, see Hinton et al., 2014, \"Distilling the knowledge in\n",
        "  a neural network.\"\n",
        "\n",
        "  Args:\n",
        "    teacher_logits: A Tensor of logits provided by the teacher.\n",
        "    student_logits: A Tensor of logits provided by the student, of the same\n",
        "      shape as `teacher_logits`.\n",
        "    temperature: Temperature to use for distillation.\n",
        "\n",
        "  Returns:\n",
        "    A scalar Tensor containing the distillation loss.\n",
        "  \"\"\"\n",
        " # your code start from here for step 3\n",
        "  soft_targets = tf.nn.softmax(teacher_logits/temperature)\n",
        "\n",
        "  return tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(\n",
        "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
        "\n",
        "def compute_student_loss(images, labels, ALPHA, DISTILLATION_TEMPERATURE):\n",
        "  \"\"\"Compute subclass knowledge distillation student loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  student_subclass_logits = student_mobile(images, training=True) # fc model\n",
        "\n",
        "  # Compute subclass distillation loss between student subclass logits and\n",
        "  # softened teacher subclass targets probabilities.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  teacher_subclass_logits = teacher_res(images, training=False) # cnn_model\n",
        "  distillation_loss_value = distillation_loss(teacher_subclass_logits, student_subclass_logits,\n",
        "                      DISTILLATION_TEMPERATURE)\n",
        "\n",
        "  # Compute cross-entropy loss with hard targets.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  cross_entropy_loss_value = tf.keras.losses.CategoricalCrossentropy(from_logits=True)(labels, student_subclass_logits)\n",
        "\n",
        "  return ALPHA * distillation_loss_value + (1-ALPHA)* cross_entropy_loss_value"
      ],
      "metadata": {
        "id": "J6xV9FbN9P43"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def compute_num_correct(model, images, labels):\n",
        "  \"\"\"Compute number of correctly classified images in a batch.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Number of correctly classified images.\n",
        "  \"\"\"\n",
        "  class_logits = model(images, training=False)\n",
        "  return tf.reduce_sum(\n",
        "      tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),\n",
        "              tf.float32)), tf.argmax(class_logits, -1), tf.argmax(labels, -1)\n",
        "\n",
        "\n",
        "def train_and_evaluate(model, compute_loss_fn):\n",
        "  \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # your code start from here for step 4\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "  NUM_EPOCHS = 10\n",
        "  for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    for images, labels in train_set:\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4\n",
        "\n",
        "        loss_value = compute_loss_fn(images,labels)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = builder.info.splits['test'].num_examples\n",
        "    for images, labels in test_set:\n",
        "      # your code start from here for step 4\n",
        "      num_correct += compute_num_correct(model,images,labels)[0]\n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QT9rVAug-XHp"
      },
      "execution_count": 45,
      "outputs": []
    }
  ]
}